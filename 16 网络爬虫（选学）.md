# 1 爬虫的介绍

## 01 课程计划

1. 入门程序
2. 网络爬虫介绍
3. HttpClient花去数据
4. Jsoup解析数据
5. 爬虫案例

## 02 入门程序

- 网络爬虫（Web crawler），是一种按照一定的规则，自动获取万维网信息的程序或脚本

1. 构建Maven工程，导入所需要的依赖

   ```
   <!--获取数据的-->
   <dependency>
   <groupId>org.apache.httpcomponents</groupId>
   <artifactId>httpclient</artifactId>
   <version>4.5.2</version>
   </dependency>
   
   <!--日志-->
   <dependency>
   <groupId>org.slf4j</groupId>
   <artifactId>slf4j-log4j12</artifactId>
   <version>1.7.2</version>
    <!--<scope>test</scope>--><!--表示测试可用-->
   </dependency>
   ```

2. 代码

   ```
   public class CrawlerFirst {
       public static void main(String[] args) throws Exception {
           // 1. 打开浏览器
           CloseableHttpClient httpClient = HttpClients.createDefault();
           // 2. 输入网址
           HttpGet httpGet = new HttpGet(" https://www.jd.com/");
           // 3. 按回车，发起请求，返回响应
           CloseableHttpResponse response = httpClient.execute(httpGet);
           // 4. 解析响应，获取数据
           if (response.getStatusLine().getStatusCode() == 200){
               HttpEntity httpEntity = response.getEntity();
   
               String content = EntityUtils.toString(httpEntity,"utf8");
               System.out.println(content);
           }
       }
   }
   ```


3. 报错` Illegal character in scheme name at index 0:  https://www.jd.com/`，如下图所示：

  ![1](C:\Users\ben\Desktop\hyzh\images\16 网络爬虫(选学)\1.png)

  原因：`HttpGet httpGet = new HttpGet(" https://www.jd.com/");`地址前多了一个空格，去掉即可

## 03 网络爬虫介绍

- 从功能上讲，爬虫一般分为三个部分：**采集、处理、存储**。

## 04 为什么要学网络爬虫

1. 可以实现搜索引擎
   - 可以实现私人的搜索引擎
2. 大数据时代，可以让我们获取更多的数据源
3. 可以更好地进行搜索引擎优化
4. 有利于就业

# 2 HttpClient

## 01HttpClient--Get

**HttpGetTest.java**

```
public class HttpGetTest {
    public static void main(String[] args) {
        // 创建HttpClient对象
        CloseableHttpClient httpClient = HttpClients.createDefault();
        // 创建HttpGet对象，设置url访问地址
        HttpGet httpGet = new HttpGet("https://www.jd.com/:");
        // 使用HttpClient发起请求，获取response

        CloseableHttpResponse response = null;
        try {
            response = httpClient.execute(httpGet);

            // 解析响应
            if (response.getStatusLine().getStatusCode() == 200){
                String content = EntityUtils.toString(response.getEntity(),"utf8");
                System.out.println(content.length());
            }
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            // 关闭response
            try {
                response.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
            // 关闭HttpClient
            try {
                httpClient.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

    }
}
```

## 02 HttpClient--Get带参数 

关键代码

```
// 创建urlBulider
URIBuilder uriBuilder = new URIBuilder("https://search.jd.com/Search");
uriBuilder.setParameter("keyword","手机")
		.setParameter("enc","utf-8")
		.setParameter("wq","手机");

// 创建HttpGet对象，设置url访问地址
HttpGet httpGet = new HttpGet(uriBuilder.build());
```

- 有多个参数，则**setParameter**多次

## 03 HttpClient--Post 

```
// 创建HttpPost对象，设置url访问地址
HttpPost httpPost = new HttpPost("https://www.jd.com/");
```

## 04 HttpClient--Post带参数 

关键代码

```
// 创建HttpPost对象，设置url访问地址
HttpPost httpPost = new HttpPost("https://search.jd.com/Search");
// 声明List集合，封装表单中的参数
List<NameValuePair> params = new ArrayList<NameValuePair>();
params.add(new BasicNameValuePair("keyword","手机"));
params.add(new BasicNameValuePair("enc","utf-8"));
// 创建表单的Entity对象，第一个对象时封装好的表单数据，第二个参数是编码
UrlEncodedFormEntity formEntity = new UrlEncodedFormEntity(params,"utf8");
// 设置表单中的Entity对象到Post请求中
httpPost.setEntity(formEntity);
// 使用HttpClient发起请求，获取response
 
```

## 05 HttpClient--连接池

**HttpClientPoolTest.java**

```
public class HttpClientPoolTest {
    public static void main(String[] args) {
        // 创建连接池管理器
        PoolingHttpClientConnectionManager connectionManager = new PoolingHttpClientConnectionManager();

        // 设置最大连接数
        connectionManager.setMaxTotal(100);
        // 设置每个主机的最大连接数
        connectionManager.setDefaultMaxPerRoute(10);

        // 使用连接池管理发起请求
        doGet(connectionManager);
        doGet(connectionManager);
        doPost(connectionManager);        
    }

    private static void doGet(PoolingHttpClientConnectionManager connectionManager) {
        // 不是每次创建新的HttpClient，而是从连接池中获取HttpClient对象
        CloseableHttpClient httpClient = HttpClients.custom().setConnectionManager(connectionManager).build();

        HttpGet httpGet = new HttpGet("https://www.jd.com/");
        CloseableHttpResponse response = null;
        try {
            response = httpClient.execute(httpGet);

            if (response.getStatusLine().getStatusCode() == 200){
                String content = EntityUtils.toString(response.getEntity(),"utf8");
                System.out.println(content.length());
            }
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            if (response != null){
                try {
                    response.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
                // 不能关闭 HttpClient，由连接池管理HttpClient
                // httpClient.close();
            }


        }
    }
    private static void doPost(PoolingHttpClientConnectionManager connectionManager) {
    }
}
```

## 05 HttpClient--请求参数

相关代码

```
// 配置请求信息
RequestConfig config = RequestConfig.custom().setConnectTimeout(1000) // 创建连接的最长时间，单位是毫秒
    .setConnectionRequestTimeout(500) // 设置连接获取的最长时间，单位是毫秒
    .setSocketTimeout(10*1000) // 设置数据传输的最长时间，单位是毫秒
    .build();
// 给请求设置请求信息
httpGet.setConfig(config);
```

# 3 Jsoup解析